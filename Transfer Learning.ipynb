{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_0zs3TflcAEr"
   },
   "source": [
    "<pre>\n",
    "1. Download all the data in this folder https://drive.google.com/open?id=1Z4TyI7FcFVEx8qdl4jO9qxvxaqLSqoEu. it contains two file both images and labels. The label file list the images and their categories in the following format:\n",
    "            <b>path/to/the/image.tif,category</b>\n",
    "            \n",
    "    where the categories are numbered 0 to 15, in the following order:\n",
    "\n",
    "    <b>0 letter\n",
    "    1 form\n",
    "    2 email\n",
    "    3 handwritten\n",
    "    4 advertisement\n",
    "    5 scientific report\n",
    "    6 scientific publication\n",
    "    7 specification\n",
    "    8 file folder\n",
    "    9 news article\n",
    "    10 budget\n",
    "    11 invoice\n",
    "    12 presentation\n",
    "    13 questionnaire\n",
    "    14 resume\n",
    "    15 memo</b>\n",
    "    \n",
    "2. On this image data, you have to train 3 types of models as given below. You have to split the data into Train and Validation data.\n",
    "\n",
    "3. Try not to load all the images into memory, use the gernarators that we have given the reference notebooks to load the batch of images only during the train data.\n",
    "or you can use this method also\n",
    "<a href='https://medium.com/@vijayabhaskar96/tutorial-on-keras-imagedatagenerator-with-flow-from-dataframe-8bd5776e45c1'>https://medium.com/@vijayabhaskar96/tutorial-on-keras-imagedatagenerator-with-flow-from-dataframe-8bd5776e45c1</a>\n",
    "\n",
    "<a href='https://medium.com/@vijayabhaskar96/tutorial-on-keras-flow-from-dataframe-1fd4493d237c'>https://medium.com/@vijayabhaskar96/tutorial-on-keras-flow-from-dataframe-1fd4493d237c</a>\n",
    "\n",
    "\n",
    "4. You are free to choose Learning rate, optimizer, loss function, image augmentation, any hyperparameters. but you have to use the same architechture what we are asking below. \n",
    "\n",
    "5. Use tensorboard for every model and analyse your gradients. (you need to upload the screenshots for each model for evaluation)\n",
    "\n",
    "Note: fit_genarator() method will have problems with the tensorboard histograms, try to debug it, if you could not do use histgrams=0 i.e don't include histograms, check the documentation of tensorboard for more information. \n",
    "\n",
    "6. You can check about Transfer Learning in this link - <a href='https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html'>https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html</a>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XZXpEZtJcAEu"
   },
   "source": [
    "### Model-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EF12MYu1cAEy"
   },
   "source": [
    "<pre>\n",
    "1. Use <a href='https://www.tensorflow.org/api_docs/python/tf/keras/applications/VGG16'>VGG-16</a> pretrained network without Fully Connected layers and initilize all the weights with Imagenet trained weights. \n",
    "2. After VGG-16 network without FC layers, add a new Conv block ( 1 Conv layer and 1 Maxpooling ), 2 FC layers and a output layer to classify 16 classes. You are free to choose any hyperparameters/parameters of conv block, FC layers, output layer. \n",
    "3. Final architecture will be <b>INPUT --> VGG-16 without Top layers(FC) --> Conv Layer --> Maxpool Layer --> 2 FC layers --> Output Layer</b>\n",
    "4. Train only new Conv block, FC layers, output layer. Don't train the VGG-16 network. \n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\salma\\anaconda3\\envs\\finalgpu\\lib\\site-packages (2.6.0)\n"
     ]
    }
   ],
   "source": [
    "#!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall keras-preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install git+https://github.com/keras-team/keras-preprocessing.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_labels = pd.read_csv('rvl-cdip/labels_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>imagesv/v/o/h/voh71d00/509132755+-2755.tif</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>imagesl/l/x/t/lxt19d00/502213303.tif</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>imagesx/x/e/d/xed05a00/2075325674.tif</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>imageso/o/j/b/ojb60d00/517511301+-1301.tif</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>imagesq/q/z/k/qzk17e00/2031320195.tif</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         path  label\n",
       "0  imagesv/v/o/h/voh71d00/509132755+-2755.tif      3\n",
       "1        imagesl/l/x/t/lxt19d00/502213303.tif      3\n",
       "2       imagesx/x/e/d/xed05a00/2075325674.tif      2\n",
       "3  imageso/o/j/b/ojb60d00/517511301+-1301.tif      3\n",
       "4       imagesq/q/z/k/qzk17e00/2031320195.tif      7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import regularizers, optimizers \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36000 validated image filenames.\n",
      "Found 12000 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "#https://vijayabhaskar96.medium.com/tutorial-on-keras-flow-from-dataframe-1fd4493d237c\n",
    "datagen=ImageDataGenerator(rescale=1./255.,validation_split=0.25)\n",
    "\n",
    "train_generator=datagen.flow_from_dataframe(\n",
    "dataframe=total_labels,\n",
    "directory=\"rvl-cdip/data_final\",\n",
    "x_col=\"path\",\n",
    "y_col=\"label\",\n",
    "subset=\"training\",\n",
    "batch_size=32,\n",
    "seed=42,\n",
    "shuffle=True,\n",
    "class_mode=\"raw\",\n",
    "target_size=(224,224))\n",
    "\n",
    "valid_generator=datagen.flow_from_dataframe(\n",
    "dataframe=total_labels,\n",
    "directory=\"rvl-cdip/data_final\",\n",
    "x_col=\"path\",\n",
    "y_col=\"label\",\n",
    "subset=\"validation\",\n",
    "batch_size=32,\n",
    "seed=42,\n",
    "shuffle=True,\n",
    "class_mode=\"raw\",\n",
    "target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of train labels:  36000\n",
      "len of valid labels:  12000\n"
     ]
    }
   ],
   "source": [
    "print('len of train labels: ',len(train_generator.labels))\n",
    "print('len of valid labels: ',len(valid_generator.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1125 batches: 249.88824820518494 s\n",
      "144.06440 Images/s\n"
     ]
    }
   ],
   "source": [
    "##Checking time taken to load images. \n",
    "import time\n",
    "start = time.time()\n",
    "total_batches = 0\n",
    "\n",
    "batches = 0\n",
    "per_batch = 32\n",
    "for x_batch, y_batch in train_generator:\n",
    "    batches += 1\n",
    "    if batches >= 36000/per_batch:\n",
    "        total_batches = total_batches + batches\n",
    "        break \n",
    "end = time.time()\n",
    "duration = end-start\n",
    "print(\"{} batches: {} s\".format(total_batches, duration))\n",
    "print(\"{:0.5f} Images/s\".format(per_batch*total_batches/duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375 batches: 86.22054624557495 s\n",
      "139.17796 Images/s\n"
     ]
    }
   ],
   "source": [
    "##Checking time taken to load images. \n",
    "import time\n",
    "start = time.time()\n",
    "total_batches = 0\n",
    "\n",
    "batches = 0\n",
    "per_batch = 32\n",
    "for x_batch, y_batch in valid_generator:\n",
    "    batches += 1\n",
    "    if batches >= 12000/per_batch:\n",
    "        total_batches = total_batches + batches\n",
    "        break \n",
    "end = time.time()\n",
    "duration = end-start\n",
    "print(\"{} batches: {} s\".format(total_batches, duration))\n",
    "print(\"{:0.5f} Images/s\".format(per_batch*total_batches/duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense,Input,Conv2D,MaxPool2D,Activation,Dropout,Flatten,BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "import random as rn\n",
    "from tensorflow.keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "np.random.seed(0)\n",
    "rn.seed(0)\n",
    "\n",
    "model_1 = VGG16(weights='imagenet', include_top=False,input_shape=(224,224,3))\n",
    "model_1.trainable = False\n",
    "model_1_out = model_1.output \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1 False\n",
      "1 block1_conv1 False\n",
      "2 block1_conv2 False\n",
      "3 block1_pool False\n",
      "4 block2_conv1 False\n",
      "5 block2_conv2 False\n",
      "6 block2_pool False\n",
      "7 block3_conv1 False\n",
      "8 block3_conv2 False\n",
      "9 block3_conv3 False\n",
      "10 block3_pool False\n",
      "11 block4_conv1 False\n",
      "12 block4_conv2 False\n",
      "13 block4_conv3 False\n",
      "14 block4_pool False\n",
      "15 block5_conv1 False\n",
      "16 block5_conv2 False\n",
      "17 block5_conv3 False\n",
      "18 block5_pool False\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model_1.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conv Layer\n",
    "conv1 = Conv2D(filters=512,kernel_size=(3,3),strides=(1,1),padding='valid',data_format='channels_last',\n",
    "              activation='relu',kernel_initializer=tf.keras.initializers.he_normal(seed=0),name='Conv1')(model_1_out)\n",
    "\n",
    "#MaxPool Layer\n",
    "mxPool1 = MaxPool2D(pool_size=(3,3),strides=(1,1),padding='valid',data_format='channels_last',name='Pool1')(conv1)\n",
    "\n",
    "#Flatten\n",
    "flatten = Flatten(data_format='channels_last',name='Flatten')(mxPool1)\n",
    "\n",
    "#FC layer\n",
    "FC1 = Dense(units=256,activation='relu',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0),name='FC1')(flatten)\n",
    "\n",
    "#FC layer\n",
    "FC2 = Dense(units=64,activation='relu',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0),name='FC2')(FC1)\n",
    "\n",
    "#output layer\n",
    "Out = Dense(units=16,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(seed=0),name='Output')(FC2)\n",
    "\n",
    "#Creating a model\n",
    "model = Model(inputs=model_1.input,outputs=Out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "Conv1 (Conv2D)               (None, 5, 5, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "Pool1 (MaxPooling2D)         (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               1179904   \n",
      "_________________________________________________________________\n",
      "FC2 (Dense)                  (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 16)                1040      \n",
      "=================================================================\n",
      "Total params: 18,271,888\n",
      "Trainable params: 3,557,200\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_update(epoch,lr):\n",
    "    if epoch%5 == 0 and lr>1e-4:\n",
    "        return lr - (0.1*lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import TerminateOnNaN\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "import datetime\n",
    "\n",
    "log_dir=\"logs1/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1, write_graph=True)\n",
    "\n",
    "path=\"checkpts/model1_save.hdf5\"\n",
    "model_check = ModelCheckpoint(filepath=path, monitor='val_accuracy',  verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "terminate = TerminateOnNaN()\n",
    "learning_rate = LearningRateScheduler(lr_update,verbose=1)\n",
    "\n",
    "early_stop = EarlyStopping(monitor=\"val_accuracy\",patience=5,mode='auto')\n",
    "\n",
    "call_back=[tensorboard,model_check,terminate,learning_rate,early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0009000000427477062.\n",
      "1125/1125 [==============================] - 789s 700ms/step - loss: 1.4132 - accuracy: 0.5672 - val_loss: 1.1250 - val_accuracy: 0.6654\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66542, saving model to checkpts\\model1_save.hdf5\n",
      "Epoch 2/30\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.0009000000427477062.\n",
      "1125/1125 [==============================] - 1328s 1s/step - loss: 0.9873 - accuracy: 0.6936 - val_loss: 0.9938 - val_accuracy: 0.6998\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.66542 to 0.69975, saving model to checkpts\\model1_save.hdf5\n",
      "Epoch 3/30\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0009000000427477062.\n",
      "1125/1125 [==============================] - 1470s 1s/step - loss: 0.8359 - accuracy: 0.7433 - val_loss: 0.9394 - val_accuracy: 0.7198\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.69975 to 0.71983, saving model to checkpts\\model1_save.hdf5\n",
      "Epoch 4/30\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0009000000427477062.\n",
      "1125/1125 [==============================] - 403s 358ms/step - loss: 0.7280 - accuracy: 0.7748 - val_loss: 0.8967 - val_accuracy: 0.7380\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.71983 to 0.73800, saving model to checkpts\\model1_save.hdf5\n",
      "Epoch 5/30\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.0009000000427477062.\n",
      "1125/1125 [==============================] - 404s 359ms/step - loss: 0.6387 - accuracy: 0.8004 - val_loss: 0.9429 - val_accuracy: 0.7293\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.73800\n",
      "Epoch 6/30\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0008100000384729355.\n",
      "1125/1125 [==============================] - 404s 359ms/step - loss: 0.5454 - accuracy: 0.8278 - val_loss: 0.9251 - val_accuracy: 0.7415\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.73800 to 0.74150, saving model to checkpts\\model1_save.hdf5\n",
      "Epoch 7/30\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.0008100000559352338.\n",
      "1125/1125 [==============================] - 406s 361ms/step - loss: 0.4834 - accuracy: 0.8500 - val_loss: 0.9699 - val_accuracy: 0.7270\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.74150\n",
      "Epoch 8/30\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.0008100000559352338.\n",
      "1125/1125 [==============================] - 406s 361ms/step - loss: 0.4309 - accuracy: 0.8636 - val_loss: 0.9872 - val_accuracy: 0.7471\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.74150 to 0.74708, saving model to checkpts\\model1_save.hdf5\n",
      "Epoch 9/30\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.0008100000559352338.\n",
      "1125/1125 [==============================] - 406s 361ms/step - loss: 0.3801 - accuracy: 0.8797 - val_loss: 1.0268 - val_accuracy: 0.7420\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.74708\n",
      "Epoch 10/30\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.0008100000559352338.\n",
      "1125/1125 [==============================] - 406s 361ms/step - loss: 0.3368 - accuracy: 0.8923 - val_loss: 1.0259 - val_accuracy: 0.7538\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.74708 to 0.75375, saving model to checkpts\\model1_save.hdf5\n",
      "Epoch 11/30\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.0007290000503417104.\n",
      "1125/1125 [==============================] - 407s 361ms/step - loss: 0.2849 - accuracy: 0.9075 - val_loss: 1.1279 - val_accuracy: 0.7564\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.75375 to 0.75642, saving model to checkpts\\model1_save.hdf5\n",
      "Epoch 12/30\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.0007290000794455409.\n",
      "1125/1125 [==============================] - 669s 594ms/step - loss: 0.2489 - accuracy: 0.9176 - val_loss: 1.1649 - val_accuracy: 0.7502\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.75642\n",
      "Epoch 13/30\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.0007290000794455409.\n",
      "1125/1125 [==============================] - 837s 744ms/step - loss: 0.2211 - accuracy: 0.9273 - val_loss: 1.2582 - val_accuracy: 0.7462\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.75642\n",
      "Epoch 14/30\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.0007290000794455409.\n",
      "1125/1125 [==============================] - 983s 874ms/step - loss: 0.2074 - accuracy: 0.9309 - val_loss: 1.2835 - val_accuracy: 0.7492\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.75642\n",
      "Epoch 15/30\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.0007290000794455409.\n",
      "1125/1125 [==============================] - 403s 358ms/step - loss: 0.1786 - accuracy: 0.9411 - val_loss: 1.3668 - val_accuracy: 0.7441\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.75642\n",
      "Epoch 16/30\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.0006561000715009868.\n",
      "1125/1125 [==============================] - 406s 361ms/step - loss: 0.1385 - accuracy: 0.9540 - val_loss: 1.4746 - val_accuracy: 0.7458\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.75642\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23458a20d60>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator,steps_per_epoch=1125,epochs=30,validation_data=valid_generator,validation_steps=375,callbacks=call_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 10520), started 1 day, 16:11:04 ago. (Use '!kill 10520' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6aa03f7e92769b08\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6aa03f7e92769b08\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs1/fit/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"model1/accuracy.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"model1/graph.png\">\n",
    "<img src=\"model1/distributions.png\">\n",
    "<img src=\"model1/histograms.png\">\n",
    "<img src=\"model1/timeseries.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "De0UlsaOcAE1"
   },
   "source": [
    "### Model-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CNXN3EXFcAE5"
   },
   "source": [
    "<pre>\n",
    "1. Use <a href='https://www.tensorflow.org/api_docs/python/tf/keras/applications/VGG16'>VGG-16</a> pretrained network without Fully Connected layers and initilize all the weights with Imagenet trained weights.\n",
    "2. After VGG-16 network without FC layers, don't use FC layers, use conv layers only as Fully connected layer. any FC layer can be converted to a CONV layer. This conversion will reduce the No of Trainable parameters in FC layers. For example, an FC layer with K=4096 that is looking at some input volume of size 7×7×512 can be equivalently expressed as a CONV layer with F=7,P=0,S=1,K=4096. In other words, we are setting the filter size to be exactly the size of the input volume, and hence the output will simply be 1×1×4096 since only a single depth column “fits” across the input volume, giving identical result as the initial FC layer. You can refer <a href='http://cs231n.github.io/convolutional-networks/#convert'>this</a> link to better understanding of using Conv layer in place of fully connected layers.\n",
    "3. Final architecture will be VGG-16 without FC layers(without top), 2 Conv layers identical to FC layers, 1 output layer for 16 class classification. <b>INPUT --> VGG-16 without Top layers(FC) --> 2 Conv Layers identical to FC --> Output Layer</b>\n",
    "3. Train only last 2 Conv layers identical to FC layers, 1 output layer. Don't train the VGG-16 network. \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = VGG16(weights='imagenet', include_top=False,input_shape=(224,224,3))\n",
    "model2.trainable = False\n",
    "model2_out = model2.output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_3 False\n",
      "1 block1_conv1 False\n",
      "2 block1_conv2 False\n",
      "3 block1_pool False\n",
      "4 block2_conv1 False\n",
      "5 block2_conv2 False\n",
      "6 block2_pool False\n",
      "7 block3_conv1 False\n",
      "8 block3_conv2 False\n",
      "9 block3_conv3 False\n",
      "10 block3_pool False\n",
      "11 block4_conv1 False\n",
      "12 block4_conv2 False\n",
      "13 block4_conv3 False\n",
      "14 block4_pool False\n",
      "15 block5_conv1 False\n",
      "16 block5_conv2 False\n",
      "17 block5_conv3 False\n",
      "18 block5_pool False\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model2.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding='valid',data_format='channels_last',\n",
    "              activation='relu',kernel_initializer=tf.keras.initializers.he_normal(),name='Conv1')(model2_out)\n",
    "\n",
    "\n",
    "conv2 = Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),padding='valid',data_format='channels_last',\n",
    "              activation='relu',kernel_initializer=tf.keras.initializers.he_normal(),name='Conv2')(conv1)\n",
    "\n",
    "\n",
    "flatten = Flatten(data_format='channels_last',name='Flatten')(conv2)\n",
    "\n",
    "\n",
    "Out2 = Dense(units=16,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(seed=3),name='Output')(flatten)\n",
    "\n",
    "#model2\n",
    "model2_final = Model(inputs=model2.input,outputs=Out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "Conv1 (Conv2D)               (None, 5, 5, 256)         1179904   \n",
      "_________________________________________________________________\n",
      "Conv2 (Conv2D)               (None, 3, 3, 64)          147520    \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 16)                9232      \n",
      "=================================================================\n",
      "Total params: 16,051,344\n",
      "Trainable params: 1,336,656\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir=\"logs2/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1, write_graph=True)\n",
    "\n",
    "path=\"checkpts/model2_save.hdf5\"\n",
    "model_check = ModelCheckpoint(filepath=path, monitor='val_accuracy',  verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "terminate = TerminateOnNaN()\n",
    "learning_rate = LearningRateScheduler(lr_update,verbose=1)\n",
    "\n",
    "early_stop = EarlyStopping(monitor=\"val_accuracy\",patience=5,mode='auto')\n",
    "\n",
    "call_back=[tensorboard,model_check,terminate,learning_rate,early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_final.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0009000000427477062.\n",
      "1125/1125 [==============================] - 1022s 908ms/step - loss: 1.4010 - accuracy: 0.5738 - val_loss: 1.1482 - val_accuracy: 0.6567\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.65667, saving model to checkpts\\model2_save.hdf5\n",
      "Epoch 2/50\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.0009000000427477062.\n",
      "1125/1125 [==============================] - 462s 410ms/step - loss: 1.0181 - accuracy: 0.6902 - val_loss: 1.0177 - val_accuracy: 0.6988\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.65667 to 0.69883, saving model to checkpts\\model2_save.hdf5\n",
      "Epoch 3/50\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0009000000427477062.\n",
      "1125/1125 [==============================] - 400s 356ms/step - loss: 0.8724 - accuracy: 0.7320 - val_loss: 1.0363 - val_accuracy: 0.6954\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.69883\n",
      "Epoch 4/50\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0009000000427477062.\n",
      "1125/1125 [==============================] - 402s 357ms/step - loss: 0.7625 - accuracy: 0.7652 - val_loss: 1.0231 - val_accuracy: 0.6971\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.69883\n",
      "Epoch 5/50\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.0009000000427477062.\n",
      "1125/1125 [==============================] - 402s 357ms/step - loss: 0.6649 - accuracy: 0.7953 - val_loss: 1.0335 - val_accuracy: 0.7168\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.69883 to 0.71675, saving model to checkpts\\model2_save.hdf5\n",
      "Epoch 6/50\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0008100000384729355.\n",
      "1125/1125 [==============================] - 400s 356ms/step - loss: 0.5623 - accuracy: 0.8246 - val_loss: 1.0015 - val_accuracy: 0.7236\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.71675 to 0.72358, saving model to checkpts\\model2_save.hdf5\n",
      "Epoch 7/50\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.0008100000559352338.\n",
      "1125/1125 [==============================] - 405s 360ms/step - loss: 0.4878 - accuracy: 0.8491 - val_loss: 1.0299 - val_accuracy: 0.7253\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.72358 to 0.72533, saving model to checkpts\\model2_save.hdf5\n",
      "Epoch 8/50\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.0008100000559352338.\n",
      "1125/1125 [==============================] - 401s 356ms/step - loss: 0.4281 - accuracy: 0.8671 - val_loss: 1.1210 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.72533\n",
      "Epoch 9/50\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.0008100000559352338.\n",
      "1125/1125 [==============================] - 401s 356ms/step - loss: 0.3808 - accuracy: 0.8787 - val_loss: 1.2000 - val_accuracy: 0.7149\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.72533\n",
      "Epoch 10/50\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.0008100000559352338.\n",
      "1125/1125 [==============================] - 400s 356ms/step - loss: 0.3303 - accuracy: 0.8947 - val_loss: 1.2163 - val_accuracy: 0.7140\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.72533\n",
      "Epoch 11/50\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.0007290000503417104.\n",
      "1125/1125 [==============================] - 400s 356ms/step - loss: 0.2654 - accuracy: 0.9162 - val_loss: 1.2994 - val_accuracy: 0.7223\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.72533\n",
      "Epoch 12/50\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.0007290000794455409.\n",
      "1125/1125 [==============================] - 400s 356ms/step - loss: 0.2381 - accuracy: 0.9228 - val_loss: 1.3333 - val_accuracy: 0.7255\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.72533 to 0.72550, saving model to checkpts\\model2_save.hdf5\n",
      "Epoch 13/50\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.0007290000794455409.\n",
      "1125/1125 [==============================] - 400s 356ms/step - loss: 0.2040 - accuracy: 0.9343 - val_loss: 1.4267 - val_accuracy: 0.7182\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.72550\n",
      "Epoch 14/50\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.0007290000794455409.\n",
      "1125/1125 [==============================] - 400s 356ms/step - loss: 0.1823 - accuracy: 0.9412 - val_loss: 1.4622 - val_accuracy: 0.7201\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.72550\n",
      "Epoch 15/50\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.0007290000794455409.\n",
      "1125/1125 [==============================] - 443s 394ms/step - loss: 0.1649 - accuracy: 0.9469 - val_loss: 1.5099 - val_accuracy: 0.7125\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.72550\n",
      "Epoch 16/50\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.0006561000715009868.\n",
      "1125/1125 [==============================] - 736s 654ms/step - loss: 0.1203 - accuracy: 0.9612 - val_loss: 1.6333 - val_accuracy: 0.7138\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.72550\n",
      "Epoch 17/50\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.0006561000482179224.\n",
      "1125/1125 [==============================] - 746s 663ms/step - loss: 0.1133 - accuracy: 0.9623 - val_loss: 1.7880 - val_accuracy: 0.7197\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.72550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23459b22370>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_final.fit(train_generator,steps_per_epoch=1125,epochs=50,validation_data=valid_generator,validation_steps=375,callbacks=call_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 11020), started 1 day, 1:06:11 ago. (Use '!kill 11020' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-80ddf8a58cf0a47e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-80ddf8a58cf0a47e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs2/fit/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"model2/accuracy.png\">\n",
    "<img src=\"model2/graph.png\">\n",
    "<img src=\"model2/distributions.png\">\n",
    "<img src=\"model2/histograms.png\">\n",
    "<img src=\"model2/timeseries.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "amKbfojfcAE-"
   },
   "source": [
    "### Model-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N9AULF-PcAFC"
   },
   "source": [
    "<pre>\n",
    "1. Use same network as Model-2 '<b>INPUT --> VGG-16 without Top layers(FC) --> 2 Conv Layers identical to FC --> Output Layer</b>' and train only Last 6 Layers of VGG-16 network, 2 Conv layers identical to FC layers, 1 output layer.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "\n",
    "##https://keras.io/getting-started/faq/#how-can-i-obtain-reproducible-results-using-keras-during-development\n",
    "## Have to clear the session. If you are not clearing, Graph will create again and again and graph size will increses. \n",
    "## Varibles will also set to some value from before session\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "## Set the random seed values to regenerate the model.\n",
    "np.random.seed(0)\n",
    "rn.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 2, 5]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst5=[1,4,2,5,2,7,3,6]\n",
    "lst5[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = VGG16(weights='imagenet', include_top=False,input_shape=(224,224,3))\n",
    "#base_model.trainable = False\n",
    "for layer in model3.layers[0:-6]:\n",
    "    layer.trainable = False\n",
    "model3_out = model3.output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1 False\n",
      "1 block1_conv1 False\n",
      "2 block1_conv2 False\n",
      "3 block1_pool False\n",
      "4 block2_conv1 False\n",
      "5 block2_conv2 False\n",
      "6 block2_pool False\n",
      "7 block3_conv1 False\n",
      "8 block3_conv2 False\n",
      "9 block3_conv3 False\n",
      "10 block3_pool False\n",
      "11 block4_conv1 False\n",
      "12 block4_conv2 False\n",
      "13 block4_conv3 True\n",
      "14 block4_pool True\n",
      "15 block5_conv1 True\n",
      "16 block5_conv2 True\n",
      "17 block5_conv3 True\n",
      "18 block5_pool True\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model3.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conv\n",
    "conv1 = Conv2D(filters=512,kernel_size=(5,5),strides=(1,1),padding='valid',data_format='channels_last',\n",
    "              activation='relu',kernel_initializer=tf.keras.initializers.he_normal(),name='Conv1')(model3_out)\n",
    "\n",
    "#conv\n",
    "conv2 = Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),padding='valid',data_format='channels_last',\n",
    "              activation='relu',kernel_initializer=tf.keras.initializers.he_normal(),name='Conv2')(conv1)\n",
    "\n",
    "#flatten\n",
    "flatten = Flatten(data_format='channels_last',name='Flatten')(conv2)\n",
    "\n",
    "#out layer\n",
    "Out = Dense(units=16,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(),name='Output')(flatten)\n",
    "\n",
    "#model\n",
    "model3_final = Model(inputs=model3.input,outputs=Out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "Conv1 (Conv2D)               (None, 3, 3, 512)         6554112   \n",
      "_________________________________________________________________\n",
      "Conv2 (Conv2D)               (None, 1, 1, 64)          294976    \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 16)                1040      \n",
      "=================================================================\n",
      "Total params: 21,564,816\n",
      "Trainable params: 16,289,360\n",
      "Non-trainable params: 5,275,456\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_update(epoch,lr):\n",
    "    if epoch<=10:\n",
    "        return lr \n",
    "    else:\n",
    "        if epoch%5 == 0 and lr>1e-4:\n",
    "            return lr - (0.1*lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir=\"logs3_fi/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1, write_graph=True)\n",
    "\n",
    "path=\"checkpts/model3_save.hdf5\"\n",
    "model_check = ModelCheckpoint(filepath=path, monitor='val_accuracy',  verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "terminate = TerminateOnNaN()\n",
    "learning_rate = LearningRateScheduler(lr_update,verbose=1)\n",
    "\n",
    "early_stop = EarlyStopping(monitor=\"val_accuracy\",patience=3,mode='auto')\n",
    "\n",
    "call_back=[tensorboard,model_check,terminate,learning_rate,early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3_final.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "1125/1125 [==============================] - 538s 477ms/step - loss: 2.7892 - accuracy: 0.0611 - val_loss: 2.7727 - val_accuracy: 0.0634\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.06342, saving model to checkpts\\model3_save.hdf5\n",
      "Epoch 2/15\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "1125/1125 [==============================] - 543s 483ms/step - loss: 2.7728 - accuracy: 0.0605 - val_loss: 2.7729 - val_accuracy: 0.0635\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.06342 to 0.06350, saving model to checkpts\\model3_save.hdf5\n",
      "Epoch 3/15\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "1125/1125 [==============================] - 544s 484ms/step - loss: 2.7728 - accuracy: 0.0618 - val_loss: 2.7730 - val_accuracy: 0.0613\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.06350\n",
      "Epoch 4/15\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "1125/1125 [==============================] - 540s 480ms/step - loss: 2.7728 - accuracy: 0.0616 - val_loss: 2.7730 - val_accuracy: 0.0613\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.06350\n",
      "Epoch 5/15\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "1125/1125 [==============================] - 618s 549ms/step - loss: 2.7728 - accuracy: 0.0623 - val_loss: 2.7730 - val_accuracy: 0.0613\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.06350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23459ab25e0>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3_final.fit(train_generator,steps_per_epoch=1125,epochs=15,validation_data=valid_generator,validation_steps=375,callbacks=call_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 16540), started 2:30:25 ago. (Use '!kill 16540' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-bcc36958ab2f1d2c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-bcc36958ab2f1d2c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs3_fi/fit/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"model3/accuracy.png\">\n",
    "<img src=\"model3/graph.png\">\n",
    "<img src=\"model3/distributions.png\">\n",
    "<img src=\"model3/histograms.png\">\n",
    "<img src=\"model3/timeseries.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Transfer Learning.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
